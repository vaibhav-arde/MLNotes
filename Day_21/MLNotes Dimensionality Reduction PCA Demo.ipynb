{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dimensionality Reduction\n",
        "\n",
        "Dimensionality reduction is a process used to reduce the number of input variables in a dataset, while retaining as much relevant information as possible. It transforms high-dimensional data into a lower-dimensional space, making it more manageable and interpretable without losing important patterns or relationships.\n",
        "\n",
        "### Why Do We Need Dimensionality Reduction?\n",
        "\n",
        "1. **Curse of Dimensionality**:\n",
        "   When dealing with high-dimensional data, certain algorithms (like k-NN, clustering, or regression models) can become less effective because distances between data points become harder to measure accurately. As the number of dimensions increases, the volume of the data space increases exponentially, making the data points sparse. This is known as the \"curse of dimensionality.\"\n",
        "\n",
        "2. **Computational Efficiency**:\n",
        "   High-dimensional datasets require more computational power for both processing and storage. By reducing the number of dimensions, we reduce the computational costs associated with training machine learning models, making algorithms faster.\n",
        "\n",
        "3. **Overfitting Prevention**:\n",
        "   High-dimensional data often contain irrelevant or noisy features that do not contribute meaningfully to the prediction task. These features can lead to overfitting, where the model becomes too specific to the training data and fails to generalize to new data. Reducing dimensions helps mitigate this risk.\n",
        "\n",
        "4. **Visualization**:\n",
        "   Visualization of high-dimensional data is difficult. By reducing dimensions to two or three, it becomes easier to visualize and understand the data, revealing underlying patterns or clusters.\n",
        "\n",
        "### Motivation Behind Dimensionality Reduction\n",
        "\n",
        "1. **Data Simplification**:\n",
        "   Often, not all features in a dataset are equally important. Many features might be redundant or highly correlated. Dimensionality reduction helps simplify data by removing such redundancies and preserving only the essential features, which improves the interpretability of models.\n",
        "\n",
        "2. **Improved Model Performance**:\n",
        "   With fewer dimensions, models may become more robust and generalizable. Simplified models can also improve accuracy, as irrelevant or noisy features are removed from consideration, focusing on the most informative aspects of the data.\n",
        "\n",
        "3. **Easier Data Storage and Transmission**:\n",
        "   Lower-dimensional data is smaller in size, which reduces storage requirements and makes data transmission faster and easier, particularly when working with large datasets or streaming data.\n",
        "\n",
        "### Common Dimensionality Reduction Techniques\n",
        "\n",
        "1. **Principal Component Analysis (PCA)**:\n",
        "   PCA transforms the data into new features called \"principal components,\" which are linear combinations of the original features. These components are chosen to maximize variance, preserving the most information in the data while reducing dimensions.\n",
        "\n",
        "2. **Linear Discriminant Analysis (LDA)**:\n",
        "   LDA is a supervised dimensionality reduction technique that maximizes the separation between different classes in the data by finding the linear discriminants.\n",
        "\n",
        "3. **t-SNE (t-Distributed Stochastic Neighbor Embedding)**:\n",
        "   t-SNE is a nonlinear dimensionality reduction technique that visualizes high-dimensional data by mapping it to a lower-dimensional space (usually 2D or 3D), while preserving the local relationships between data points.\n",
        "\n",
        "4. **Autoencoders**:\n",
        "   In deep learning, autoencoders are a type of neural network used to learn compressed representations of input data, often used for dimensionality reduction in complex, nonlinear datasets.\n",
        "\n",
        "### Conclusion\n",
        "\n",
        "Dimensionality reduction helps manage the challenges of high-dimensional data by reducing noise, improving computation efficiency, preventing overfitting, and facilitating data visualization. It is a crucial step when working with large datasets, ensuring models remain accurate and interpretable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Principal Component Analysis (PCA)\n",
        "\n",
        "**Principal Component Analysis (PCA)** is a dimensionality reduction technique used to transform high-dimensional data into a lower-dimensional space while preserving as much variance (information) as possible. It is commonly used for data compression, noise reduction, and as a preprocessing step for machine learning algorithms.\n",
        "\n",
        "The core idea of PCA is to identify the directions (principal components) in which the data varies the most and project the data onto these new directions. These directions are orthogonal (perpendicular) to each other and capture the maximum variance in the dataset.\n",
        "\n",
        "### How PCA Works (Step-by-Step)\n",
        "\n",
        "1. **Standardization**: \n",
        "   Since PCA is affected by the scale of the features, it's important to standardize the dataset (mean = 0, variance = 1).\n",
        "\n",
        "2. **Covariance Matrix Calculation**: \n",
        "   The covariance matrix of the data is calculated to understand how the variables are related to each other.\n",
        "\n",
        "3. **Eigenvalues and Eigenvectors**:\n",
        "   The covariance matrix is decomposed into its **eigenvectors** and **eigenvalues**. Eigenvectors represent the directions of the new feature space, and eigenvalues represent the magnitude of variance along these directions.\n",
        "\n",
        "4. **Principal Components**: \n",
        "   The eigenvectors corresponding to the largest eigenvalues are selected as the principal components. These are the new axes onto which the data is projected.\n",
        "\n",
        "5. **Projection**: \n",
        "   The data is projected onto the selected principal components to obtain a lower-dimensional representation while retaining the maximum amount of variance.\n",
        "\n",
        "### PCA Example\n",
        "\n",
        "Let's consider a simple example where we have a dataset with two features, `X1` and `X2`.\n",
        "\n",
        "```plaintext\n",
        "X1  X2\n",
        "2   4\n",
        "3   5\n",
        "4   6\n",
        "5   7\n",
        "6   8\n",
        "```\n",
        "\n",
        "#### Step 1: Standardization\n",
        "\n",
        "Standardize the data so that both features have a mean of 0 and variance of 1.\n",
        "\n",
        "```plaintext\n",
        "Standardized data:\n",
        "X1'  X2'\n",
        "-1.41  -1.41\n",
        "-0.71  -0.71\n",
        "0.00   0.00\n",
        "0.71   0.71\n",
        "1.41   1.41\n",
        "```\n",
        "\n",
        "#### Step 2: Covariance Matrix\n",
        "\n",
        "Next, we calculate the covariance matrix of the standardized data to understand how the variables are related.\n",
        "\n",
        "```plaintext\n",
        "Covariance Matrix:\n",
        "[1  1]\n",
        "[1  1]\n",
        "```\n",
        "\n",
        "#### Step 3: Eigenvectors and Eigenvalues\n",
        "\n",
        "We compute the eigenvalues and eigenvectors of the covariance matrix. These tell us the directions and the amount of variance in those directions.\n",
        "\n",
        "```plaintext\n",
        "Eigenvalues: 2, 0\n",
        "Eigenvectors: [0.71, 0.71], [-0.71, 0.71]\n",
        "```\n",
        "\n",
        "Here, the first eigenvector `[0.71, 0.71]` corresponds to the larger eigenvalue of `2`, meaning this is the principal component that captures the most variance in the data.\n",
        "\n",
        "#### Step 4: Projection\n",
        "\n",
        "Finally, we project the data onto the new axis (the principal component).\n",
        "\n",
        "```plaintext\n",
        "Projected Data:\n",
        "PC1  \n",
        "-1.99\n",
        "-0.99\n",
        "0.00\n",
        "0.99\n",
        "1.99\n",
        "```\n",
        "\n",
        "The data has now been reduced to a single dimension (`PC1`), retaining most of the variance.\n",
        "\n",
        "### Eigenvalues and Eigenvectors in PCA\n",
        "\n",
        "- **Eigenvalues**: Eigenvalues tell us how much variance there is along each principal component. A higher eigenvalue indicates that the principal component captures more variance in the data.\n",
        "- **Eigenvectors**: Eigenvectors represent the directions (or axes) of the principal components. They are orthogonal to each other and point in the direction of maximum variance.\n",
        "\n",
        "In PCA, the eigenvector with the largest eigenvalue is the first principal component, and it explains the most variance in the data. The eigenvector with the second largest eigenvalue is the second principal component, and so on.\n",
        "\n",
        "### Interpretation of PCA\n",
        "\n",
        "- **Dimensionality Reduction**: PCA allows us to reduce the number of dimensions in the dataset by selecting only the top `k` principal components that capture most of the variance. For example, in a 3D dataset, you might reduce it to 2D by selecting the two components with the highest eigenvalues.\n",
        "  \n",
        "- **Variance Explained**: The proportion of the total variance explained by each principal component can be computed as the ratio of the corresponding eigenvalue to the sum of all eigenvalues. This is often visualized using a **scree plot**, which shows the explained variance for each component.\n",
        "\n",
        "### Applications of PCA\n",
        "\n",
        "1. **Data Compression**: PCA is used to reduce the size of datasets while preserving important patterns and structures.\n",
        "2. **Noise Reduction**: By keeping only the principal components that capture significant variance, PCA helps filter out noise in the data.\n",
        "3. **Visualization**: PCA is often used for visualizing high-dimensional data in two or three dimensions.\n",
        "\n",
        "### Conclusion\n",
        "\n",
        "PCA is a powerful tool for reducing the dimensionality of large datasets while retaining essential information. It helps alleviate the \"curse of dimensionality\" and makes data easier to visualize and work with in machine learning models. The eigenvectors and eigenvalues computed during PCA provide the principal components and their importance in explaining the variance in the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "X-quiQ2F4SWU"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "cskhwNSP4iW7"
      },
      "outputs": [],
      "source": [
        "data = np.array([[3, 7],\n",
        "                 [-4, -6],\n",
        "                 [1, -1],\n",
        "                 [7, 8],\n",
        "                 [-4, -1],\n",
        "                 [-3, -7]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "WyfiExc54s5p"
      },
      "outputs": [],
      "source": [
        "dataframe = pd.DataFrame(data, columns=['x1', 'x2'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3af1UvX16ws-"
      },
      "source": [
        "Standard Normal Form: If it contains mean as 0 and standard deviation as 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "W2AOtoOX440Z",
        "outputId": "d4c1c91b-6074-49f0-91df-a7ee76671ff7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x1</th>\n",
              "      <th>x2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-4</td>\n",
              "      <td>-6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-4</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>-3</td>\n",
              "      <td>-7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   x1  x2\n",
              "0   3   7\n",
              "1  -4  -6\n",
              "2   1  -1\n",
              "3   7   8\n",
              "4  -4  -1\n",
              "5  -3  -7"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "hYe13wT07L3c",
        "outputId": "d567198a-dd4e-45ec-9576-9435e4487267"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x1</th>\n",
              "      <th>x2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>6.000000</td>\n",
              "      <td>6.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>4.472136</td>\n",
              "      <td>6.324555</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-4.000000</td>\n",
              "      <td>-7.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>-3.750000</td>\n",
              "      <td>-4.750000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>2.500000</td>\n",
              "      <td>5.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>7.000000</td>\n",
              "      <td>8.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             x1        x2\n",
              "count  6.000000  6.000000\n",
              "mean   0.000000  0.000000\n",
              "std    4.472136  6.324555\n",
              "min   -4.000000 -7.000000\n",
              "25%   -3.750000 -4.750000\n",
              "50%   -1.000000 -1.000000\n",
              "75%    2.500000  5.000000\n",
              "max    7.000000  8.000000"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataframe.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "y4wcZ1hJ7XEi"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "dataScaled = scaler.fit_transform(dataframe)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CY0GMQta7q7s",
        "outputId": "d2a0afad-9f33-4516-d288-66a8be71264f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(dataScaled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "g6vIjTmi7pPW"
      },
      "outputs": [],
      "source": [
        "dataframe = pd.DataFrame(dataScaled, columns=['x1', 'x2'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "Xj903SJS7lgO",
        "outputId": "010da071-0aba-4d6a-fdfb-6537bc443631"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x1</th>\n",
              "      <th>x2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>6.000000e+00</td>\n",
              "      <td>6.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1.850372e-17</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.095445e+00</td>\n",
              "      <td>1.095445</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-9.797959e-01</td>\n",
              "      <td>-1.212436</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>-9.185587e-01</td>\n",
              "      <td>-0.822724</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>-2.449490e-01</td>\n",
              "      <td>-0.173205</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>6.123724e-01</td>\n",
              "      <td>0.866025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.714643e+00</td>\n",
              "      <td>1.385641</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 x1        x2\n",
              "count  6.000000e+00  6.000000\n",
              "mean   1.850372e-17  0.000000\n",
              "std    1.095445e+00  1.095445\n",
              "min   -9.797959e-01 -1.212436\n",
              "25%   -9.185587e-01 -0.822724\n",
              "50%   -2.449490e-01 -0.173205\n",
              "75%    6.123724e-01  0.866025\n",
              "max    1.714643e+00  1.385641"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataframe.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPVAE2-X48HK"
      },
      "source": [
        "1. To check whether the data is in standard normal form or not. As our data is in standard normal form, we are skipping that step of coverting our data to standard normal form."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEDx8KCE5JQm"
      },
      "source": [
        "2. Covariance Matrix between the two features that we have (x1, x2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dTktrkCj45tx",
        "outputId": "65aed166-f427-4208-ed78-ea435f8e01dd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1.2       , 1.06066017],\n",
              "       [1.06066017, 1.2       ]])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## Approach 1\n",
        "c1 = dataframe.x1\n",
        "c2 = dataframe.x2\n",
        "np.cov(c1, c2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fiAtCNg19NxW",
        "outputId": "43fa7f0a-9f65-4d2b-b678-0d907128de4c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(6, 2)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataframe.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "2NP5CU2h6kzr",
        "outputId": "77b4ea1a-c83b-4ce7-91b7-b9368c618623"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x1</th>\n",
              "      <th>x2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>x1</th>\n",
              "      <td>1.20000</td>\n",
              "      <td>1.06066</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>x2</th>\n",
              "      <td>1.06066</td>\n",
              "      <td>1.20000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         x1       x2\n",
              "x1  1.20000  1.06066\n",
              "x2  1.06066  1.20000"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## Approach 2\n",
        "covarianceMatrix = dataframe.T @ dataframe / 5\n",
        "covarianceMatrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmvO9SW67KzZ",
        "outputId": "64cb8610-2c67-439f-b54d-e73eb0f150bf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.0606601717798212"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## Approach 3\n",
        "np.sum(c1 * c2)/5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wwCenBJ8QlE"
      },
      "source": [
        "3. Evaluate the eigen values and eigen vectors of the above coorelation matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "me_Zxznw7puW"
      },
      "outputs": [],
      "source": [
        "eigenValues, eigenVectors = np.linalg.eig(covarianceMatrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BF1PMHCb8cnX",
        "outputId": "f9220c46-0cb3-4293-f15b-a3bf8fd208e3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([2.26066017, 0.13933983])"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## eigenValues = # features\n",
        "## eigenValue represents the strength of the information given by the eigenVector\n",
        "eigenValues"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LfQM1cG68is1",
        "outputId": "b235481f-dd57-410f-8d8f-17f0d9c56b37"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 0.70710678, -0.70710678],\n",
              "       [ 0.70710678,  0.70710678]])"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "eigenVectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZ-yFo8T9qv8",
        "outputId": "b04cd73b-f1df-4ccc-ff05-c0093b21ba5c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.70710678, 0.70710678])"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "eigenVectors[:, 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "YjjGdMZH-Bii",
        "outputId": "c944e832-56ce-4492-9da5-55f58df12a12"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x1</th>\n",
              "      <th>x2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.734847</td>\n",
              "      <td>1.212436</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.979796</td>\n",
              "      <td>-1.039230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.244949</td>\n",
              "      <td>-0.173205</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.714643</td>\n",
              "      <td>1.385641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.979796</td>\n",
              "      <td>-0.173205</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>-0.734847</td>\n",
              "      <td>-1.212436</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         x1        x2\n",
              "0  0.734847  1.212436\n",
              "1 -0.979796 -1.039230\n",
              "2  0.244949 -0.173205\n",
              "3  1.714643  1.385641\n",
              "4 -0.979796 -0.173205\n",
              "5 -0.734847 -1.212436"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "B9Yxg4o-8j-d"
      },
      "outputs": [],
      "source": [
        "## PC1 - Contains the maximum information of the original two features that you have\n",
        "PC1 = dataframe @ eigenVectors[:, 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNsgPRlb9T16",
        "outputId": "b21c211d-9847-4f28-a980-f171e69e8a43"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    1.376937\n",
              "1   -1.427667\n",
              "2    0.050731\n",
              "3    2.192231\n",
              "4   -0.815295\n",
              "5   -1.376937\n",
              "dtype: float64"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "PC1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4AHkl30w9VBF",
        "outputId": "15c35eae-78af-4628-ac04-ec5a7889bc56"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    0.337706\n",
              "1   -0.042027\n",
              "2   -0.295680\n",
              "3   -0.232640\n",
              "4    0.570346\n",
              "5   -0.337706\n",
              "dtype: float64"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## PC2\n",
        "PC2 = dataframe @ eigenVectors[:, 1]\n",
        "PC2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "tfnKDeun94fc",
        "outputId": "bb8a16f8-ca01-4429-97c4-6af97ce7b283"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x1</th>\n",
              "      <th>x2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.734847</td>\n",
              "      <td>1.212436</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.979796</td>\n",
              "      <td>-1.039230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.244949</td>\n",
              "      <td>-0.173205</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.714643</td>\n",
              "      <td>1.385641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.979796</td>\n",
              "      <td>-0.173205</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>-0.734847</td>\n",
              "      <td>-1.212436</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         x1        x2\n",
              "0  0.734847  1.212436\n",
              "1 -0.979796 -1.039230\n",
              "2  0.244949 -0.173205\n",
              "3  1.714643  1.385641\n",
              "4 -0.979796 -0.173205\n",
              "5 -0.734847 -1.212436"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataframe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Applications of Dimensionality reduction**\n",
        " techniques, including Principal Component Analysis (PCA), t-SNE, and others, are widely used in real-world applications to simplify complex, high-dimensional datasets while preserving key information. These techniques make data analysis more efficient, improve model performance, and reduce computational costs. Below are some real-time applications of dimensionality reduction:\n",
        "\n",
        "### 1. **Image Compression**\n",
        "   - **Application**: Dimensionality reduction techniques like PCA are used to reduce the size of image files by representing them with fewer components without losing significant detail.\n",
        "   - **Example**: JPEG compression uses PCA to reduce the dimensionality of color images, allowing for faster storage and transmission.\n",
        "\n",
        "### 2. **Facial Recognition**\n",
        "   - **Application**: In facial recognition systems, dimensionality reduction is used to reduce the complexity of the high-dimensional image data while preserving the unique features necessary to distinguish between faces.\n",
        "   - **Example**: Eigenfaces and Fisherfaces are popular methods based on PCA that reduce image data to a lower-dimensional space for faster and more accurate face recognition.\n",
        "\n",
        "### 3. **Data Visualization**\n",
        "   - **Application**: In cases where data has many dimensions (features), it is hard to visualize and analyze. Dimensionality reduction techniques help to project the data into 2D or 3D space, making it easier to explore and interpret.\n",
        "   - **Example**: t-SNE and PCA are frequently used in exploratory data analysis (EDA) to visualize complex datasets like genomic data, sensor data, or high-dimensional machine learning features.\n",
        "\n",
        "### 4. **Text Data Analysis and NLP**\n",
        "   - **Application**: Natural Language Processing (NLP) applications often deal with very high-dimensional data, such as the bag-of-words or TF-IDF representations of text. Dimensionality reduction helps in reducing the complexity of such data while retaining essential semantic information.\n",
        "   - **Example**: In topic modeling, techniques like Latent Semantic Analysis (LSA) use dimensionality reduction to find patterns and relationships in the text corpus by reducing the number of features (words) to key topics.\n",
        "\n",
        "### 5. **Recommender Systems**\n",
        "   - **Application**: Recommender systems rely on user-item interaction data, which can be extremely high-dimensional. Dimensionality reduction helps in reducing the number of latent features used to represent user preferences and item characteristics.\n",
        "   - **Example**: Matrix factorization techniques, like Singular Value Decomposition (SVD), are commonly used in collaborative filtering to predict user preferences based on lower-dimensional latent factors.\n",
        "\n",
        "### 6. **Genome Data Analysis**\n",
        "   - **Application**: Genomic data contains thousands of features representing different genes. Dimensionality reduction is crucial for analyzing this data efficiently by reducing the number of features while preserving key biological information.\n",
        "   - **Example**: PCA and t-SNE are used in genomics to identify patterns in gene expression data, classify diseases, and discover subgroups of patients with similar genetic profiles.\n",
        "\n",
        "### 7. **Anomaly Detection**\n",
        "   - **Application**: In anomaly detection, reducing the dimensionality of the data can help highlight key features that distinguish normal from abnormal behavior.\n",
        "   - **Example**: PCA is used in network security to reduce the dimensionality of network traffic data to identify abnormal patterns that may indicate cyber threats.\n",
        "\n",
        "### 8. **Sensor Data Analysis**\n",
        "   - **Application**: IoT devices and sensors generate high-dimensional data streams, making it difficult to analyze in real-time. Dimensionality reduction techniques simplify the data while retaining important signals.\n",
        "   - **Example**: PCA is used in predictive maintenance systems to reduce the dimensionality of sensor data and detect equipment failures or operational anomalies in industrial environments.\n",
        "\n",
        "### 9. **Medical Imaging**\n",
        "   - **Application**: In medical imaging, high-resolution images like MRIs and CT scans generate massive amounts of data. Dimensionality reduction helps in compressing these images and extracting essential features for diagnosis.\n",
        "   - **Example**: PCA and autoencoders are used to reduce the dimensionality of MRI or CT scan images, making them easier to process and analyze for disease detection, segmentation, or 3D reconstruction.\n",
        "\n",
        "### 10. **Speech Recognition**\n",
        "   - **Application**: Speech data is high-dimensional and complex, especially when dealing with raw audio signals. Dimensionality reduction helps in extracting important features for speech recognition systems.\n",
        "   - **Example**: Techniques like PCA or Mel-frequency cepstral coefficients (MFCCs) are used to reduce the dimensionality of audio data, making it more manageable for speech-to-text algorithms.\n",
        "\n",
        "### 11. **Financial Market Analysis**\n",
        "   - **Application**: Financial data often includes many correlated variables like stock prices, interest rates, and economic indicators. Dimensionality reduction is used to simplify this data and find patterns or trends.\n",
        "   - **Example**: PCA is used to reduce the number of correlated variables in financial data to create models that predict market movements, manage risks, or optimize portfolios.\n",
        "\n",
        "### 12. **Customer Segmentation**\n",
        "   - **Application**: In marketing and customer relationship management, dimensionality reduction is used to group customers based on behaviors, preferences, or demographics, allowing businesses to create targeted marketing strategies.\n",
        "   - **Example**: PCA can reduce customer data features like purchase history and demographics into a few key components, making it easier to segment customers for personalized offers.\n",
        "\n",
        "### 13. **Drug Discovery**\n",
        "   - **Application**: Dimensionality reduction is crucial in drug discovery, where datasets often consist of thousands of chemical compounds with numerous features.\n",
        "   - **Example**: Techniques like PCA and t-SNE are used to reduce the number of variables in chemical compound datasets, making it easier to identify promising candidates for drug development.\n",
        "\n",
        "### 14. **Robotics**\n",
        "   - **Application**: Robots often operate in complex environments, generating high-dimensional sensor data. Dimensionality reduction helps robots navigate, recognize objects, and make decisions more efficiently.\n",
        "   - **Example**: Dimensionality reduction techniques are used in robotics for object recognition, reducing the complexity of sensor data inputs and improving decision-making algorithms.\n",
        "\n",
        "---\n",
        "\n",
        "### Why Dimensionality Reduction Is Needed:\n",
        "\n",
        "- **Improves Performance**: High-dimensional data can lead to overfitting in machine learning models. Reducing dimensionality simplifies the model, making it more generalizable.\n",
        "- **Computational Efficiency**: High-dimensional data requires significant computational power. Reducing dimensions speeds up model training and prediction.\n",
        "- **Removes Noise**: Dimensionality reduction helps filter out irrelevant features, making it easier to identify underlying patterns in the data.\n",
        "- **Storage and Transmission**: In applications like image compression or sensor data analysis, dimensionality reduction reduces the data's size, making it easier to store and transmit.\n",
        "\n",
        "In summary, dimensionality reduction is a critical step in making high-dimensional data more manageable, interpretable, and computationally feasible for real-world applications across various industries."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Implimentation of Dimensionality reduction**\n",
        "Using SKlearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "cp6xn7-1-hgk"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
              "0            6      148             72             35        0  33.6   \n",
              "1            1       85             66             29        0  26.6   \n",
              "2            8      183             64              0        0  23.3   \n",
              "3            1       89             66             23       94  28.1   \n",
              "4            0      137             40             35      168  43.1   \n",
              "\n",
              "   DiabetesPedigreeFunction  Age  Outcome  \n",
              "0                     0.627   50        1  \n",
              "1                     0.351   31        0  \n",
              "2                     0.672   32        1  \n",
              "3                     0.167   21        0  \n",
              "4                     2.288   33        1  "
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = pd.read_csv('./diabetes.csv')\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**1. Check the Standard Normal Form**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>3.845052</td>\n",
              "      <td>120.894531</td>\n",
              "      <td>69.105469</td>\n",
              "      <td>20.536458</td>\n",
              "      <td>79.799479</td>\n",
              "      <td>31.992578</td>\n",
              "      <td>0.471876</td>\n",
              "      <td>33.240885</td>\n",
              "      <td>0.348958</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>3.369578</td>\n",
              "      <td>31.972618</td>\n",
              "      <td>19.355807</td>\n",
              "      <td>15.952218</td>\n",
              "      <td>115.244002</td>\n",
              "      <td>7.884160</td>\n",
              "      <td>0.331329</td>\n",
              "      <td>11.760232</td>\n",
              "      <td>0.476951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.078000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>99.000000</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>27.300000</td>\n",
              "      <td>0.243750</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>3.000000</td>\n",
              "      <td>117.000000</td>\n",
              "      <td>72.000000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>30.500000</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>0.372500</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>6.000000</td>\n",
              "      <td>140.250000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>127.250000</td>\n",
              "      <td>36.600000</td>\n",
              "      <td>0.626250</td>\n",
              "      <td>41.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>17.000000</td>\n",
              "      <td>199.000000</td>\n",
              "      <td>122.000000</td>\n",
              "      <td>99.000000</td>\n",
              "      <td>846.000000</td>\n",
              "      <td>67.100000</td>\n",
              "      <td>2.420000</td>\n",
              "      <td>81.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
              "count   768.000000  768.000000     768.000000     768.000000  768.000000   \n",
              "mean      3.845052  120.894531      69.105469      20.536458   79.799479   \n",
              "std       3.369578   31.972618      19.355807      15.952218  115.244002   \n",
              "min       0.000000    0.000000       0.000000       0.000000    0.000000   \n",
              "25%       1.000000   99.000000      62.000000       0.000000    0.000000   \n",
              "50%       3.000000  117.000000      72.000000      23.000000   30.500000   \n",
              "75%       6.000000  140.250000      80.000000      32.000000  127.250000   \n",
              "max      17.000000  199.000000     122.000000      99.000000  846.000000   \n",
              "\n",
              "              BMI  DiabetesPedigreeFunction         Age     Outcome  \n",
              "count  768.000000                768.000000  768.000000  768.000000  \n",
              "mean    31.992578                  0.471876   33.240885    0.348958  \n",
              "std      7.884160                  0.331329   11.760232    0.476951  \n",
              "min      0.000000                  0.078000   21.000000    0.000000  \n",
              "25%     27.300000                  0.243750   24.000000    0.000000  \n",
              "50%     32.000000                  0.372500   29.000000    0.000000  \n",
              "75%     36.600000                  0.626250   41.000000    1.000000  \n",
              "max     67.100000                  2.420000   81.000000    1.000000  "
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## descriptive statistics of a given data\n",
        "data.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "## input features only\n",
        "data = data.drop(columns=['Outcome'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
              "0            6      148             72             35        0  33.6   \n",
              "1            1       85             66             29        0  26.6   \n",
              "2            8      183             64              0        0  23.3   \n",
              "3            1       89             66             23       94  28.1   \n",
              "4            0      137             40             35      168  43.1   \n",
              "\n",
              "   DiabetesPedigreeFunction  Age  \n",
              "0                     0.627   50  \n",
              "1                     0.351   31  \n",
              "2                     0.672   32  \n",
              "3                     0.167   21  \n",
              "4                     2.288   33  "
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "## convert the data into standard scaler form\n",
        "## mean = 0 and standard deviation = 1\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "dataScaled = scaler.fit_transform(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.639947</td>\n",
              "      <td>0.848324</td>\n",
              "      <td>0.149641</td>\n",
              "      <td>0.907270</td>\n",
              "      <td>-0.692891</td>\n",
              "      <td>0.204013</td>\n",
              "      <td>0.468492</td>\n",
              "      <td>1.425995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.844885</td>\n",
              "      <td>-1.123396</td>\n",
              "      <td>-0.160546</td>\n",
              "      <td>0.530902</td>\n",
              "      <td>-0.692891</td>\n",
              "      <td>-0.684422</td>\n",
              "      <td>-0.365061</td>\n",
              "      <td>-0.190672</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.233880</td>\n",
              "      <td>1.943724</td>\n",
              "      <td>-0.263941</td>\n",
              "      <td>-1.288212</td>\n",
              "      <td>-0.692891</td>\n",
              "      <td>-1.103255</td>\n",
              "      <td>0.604397</td>\n",
              "      <td>-0.105584</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.844885</td>\n",
              "      <td>-0.998208</td>\n",
              "      <td>-0.160546</td>\n",
              "      <td>0.154533</td>\n",
              "      <td>0.123302</td>\n",
              "      <td>-0.494043</td>\n",
              "      <td>-0.920763</td>\n",
              "      <td>-1.041549</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1.141852</td>\n",
              "      <td>0.504055</td>\n",
              "      <td>-1.504687</td>\n",
              "      <td>0.907270</td>\n",
              "      <td>0.765836</td>\n",
              "      <td>1.409746</td>\n",
              "      <td>5.484909</td>\n",
              "      <td>-0.020496</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          0         1         2         3         4         5         6  \\\n",
              "0  0.639947  0.848324  0.149641  0.907270 -0.692891  0.204013  0.468492   \n",
              "1 -0.844885 -1.123396 -0.160546  0.530902 -0.692891 -0.684422 -0.365061   \n",
              "2  1.233880  1.943724 -0.263941 -1.288212 -0.692891 -1.103255  0.604397   \n",
              "3 -0.844885 -0.998208 -0.160546  0.154533  0.123302 -0.494043 -0.920763   \n",
              "4 -1.141852  0.504055 -1.504687  0.907270  0.765836  1.409746  5.484909   \n",
              "\n",
              "          7  \n",
              "0  1.425995  \n",
              "1 -0.190672  \n",
              "2 -0.105584  \n",
              "3 -1.041549  \n",
              "4 -0.020496  "
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataScaled = pd.DataFrame(dataScaled)\n",
        "dataScaled.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>7.680000e+02</td>\n",
              "      <td>7.680000e+02</td>\n",
              "      <td>7.680000e+02</td>\n",
              "      <td>7.680000e+02</td>\n",
              "      <td>7.680000e+02</td>\n",
              "      <td>7.680000e+02</td>\n",
              "      <td>7.680000e+02</td>\n",
              "      <td>7.680000e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>-6.476301e-17</td>\n",
              "      <td>-9.251859e-18</td>\n",
              "      <td>1.503427e-17</td>\n",
              "      <td>1.006140e-16</td>\n",
              "      <td>-3.006854e-17</td>\n",
              "      <td>2.590520e-16</td>\n",
              "      <td>2.451743e-16</td>\n",
              "      <td>1.931325e-16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.000652e+00</td>\n",
              "      <td>1.000652e+00</td>\n",
              "      <td>1.000652e+00</td>\n",
              "      <td>1.000652e+00</td>\n",
              "      <td>1.000652e+00</td>\n",
              "      <td>1.000652e+00</td>\n",
              "      <td>1.000652e+00</td>\n",
              "      <td>1.000652e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-1.141852e+00</td>\n",
              "      <td>-3.783654e+00</td>\n",
              "      <td>-3.572597e+00</td>\n",
              "      <td>-1.288212e+00</td>\n",
              "      <td>-6.928906e-01</td>\n",
              "      <td>-4.060474e+00</td>\n",
              "      <td>-1.189553e+00</td>\n",
              "      <td>-1.041549e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>-8.448851e-01</td>\n",
              "      <td>-6.852363e-01</td>\n",
              "      <td>-3.673367e-01</td>\n",
              "      <td>-1.288212e+00</td>\n",
              "      <td>-6.928906e-01</td>\n",
              "      <td>-5.955785e-01</td>\n",
              "      <td>-6.889685e-01</td>\n",
              "      <td>-7.862862e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>-2.509521e-01</td>\n",
              "      <td>-1.218877e-01</td>\n",
              "      <td>1.496408e-01</td>\n",
              "      <td>1.545332e-01</td>\n",
              "      <td>-4.280622e-01</td>\n",
              "      <td>9.419788e-04</td>\n",
              "      <td>-3.001282e-01</td>\n",
              "      <td>-3.608474e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>6.399473e-01</td>\n",
              "      <td>6.057709e-01</td>\n",
              "      <td>5.632228e-01</td>\n",
              "      <td>7.190857e-01</td>\n",
              "      <td>4.120079e-01</td>\n",
              "      <td>5.847705e-01</td>\n",
              "      <td>4.662269e-01</td>\n",
              "      <td>6.602056e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>3.906578e+00</td>\n",
              "      <td>2.444478e+00</td>\n",
              "      <td>2.734528e+00</td>\n",
              "      <td>4.921866e+00</td>\n",
              "      <td>6.652839e+00</td>\n",
              "      <td>4.455807e+00</td>\n",
              "      <td>5.883565e+00</td>\n",
              "      <td>4.063716e+00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  0             1             2             3             4  \\\n",
              "count  7.680000e+02  7.680000e+02  7.680000e+02  7.680000e+02  7.680000e+02   \n",
              "mean  -6.476301e-17 -9.251859e-18  1.503427e-17  1.006140e-16 -3.006854e-17   \n",
              "std    1.000652e+00  1.000652e+00  1.000652e+00  1.000652e+00  1.000652e+00   \n",
              "min   -1.141852e+00 -3.783654e+00 -3.572597e+00 -1.288212e+00 -6.928906e-01   \n",
              "25%   -8.448851e-01 -6.852363e-01 -3.673367e-01 -1.288212e+00 -6.928906e-01   \n",
              "50%   -2.509521e-01 -1.218877e-01  1.496408e-01  1.545332e-01 -4.280622e-01   \n",
              "75%    6.399473e-01  6.057709e-01  5.632228e-01  7.190857e-01  4.120079e-01   \n",
              "max    3.906578e+00  2.444478e+00  2.734528e+00  4.921866e+00  6.652839e+00   \n",
              "\n",
              "                  5             6             7  \n",
              "count  7.680000e+02  7.680000e+02  7.680000e+02  \n",
              "mean   2.590520e-16  2.451743e-16  1.931325e-16  \n",
              "std    1.000652e+00  1.000652e+00  1.000652e+00  \n",
              "min   -4.060474e+00 -1.189553e+00 -1.041549e+00  \n",
              "25%   -5.955785e-01 -6.889685e-01 -7.862862e-01  \n",
              "50%    9.419788e-04 -3.001282e-01 -3.608474e-01  \n",
              "75%    5.847705e-01  4.662269e-01  6.602056e-01  \n",
              "max    4.455807e+00  5.883565e+00  4.063716e+00  "
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataScaled.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(768, 8)"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataScaled.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**2. Covariance Matrix**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.001304</td>\n",
              "      <td>0.129627</td>\n",
              "      <td>0.141466</td>\n",
              "      <td>-0.081778</td>\n",
              "      <td>-0.073630</td>\n",
              "      <td>0.017706</td>\n",
              "      <td>-0.033566</td>\n",
              "      <td>0.545051</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.129627</td>\n",
              "      <td>1.001304</td>\n",
              "      <td>0.152789</td>\n",
              "      <td>0.057403</td>\n",
              "      <td>0.331789</td>\n",
              "      <td>0.221359</td>\n",
              "      <td>0.137516</td>\n",
              "      <td>0.263858</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.141466</td>\n",
              "      <td>0.152789</td>\n",
              "      <td>1.001304</td>\n",
              "      <td>0.207641</td>\n",
              "      <td>0.089049</td>\n",
              "      <td>0.282173</td>\n",
              "      <td>0.041319</td>\n",
              "      <td>0.239840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.081778</td>\n",
              "      <td>0.057403</td>\n",
              "      <td>0.207641</td>\n",
              "      <td>1.001304</td>\n",
              "      <td>0.437352</td>\n",
              "      <td>0.393085</td>\n",
              "      <td>0.184167</td>\n",
              "      <td>-0.114119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.073630</td>\n",
              "      <td>0.331789</td>\n",
              "      <td>0.089049</td>\n",
              "      <td>0.437352</td>\n",
              "      <td>1.001304</td>\n",
              "      <td>0.198117</td>\n",
              "      <td>0.185312</td>\n",
              "      <td>-0.042218</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.017706</td>\n",
              "      <td>0.221359</td>\n",
              "      <td>0.282173</td>\n",
              "      <td>0.393085</td>\n",
              "      <td>0.198117</td>\n",
              "      <td>1.001304</td>\n",
              "      <td>0.140830</td>\n",
              "      <td>0.036289</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>-0.033566</td>\n",
              "      <td>0.137516</td>\n",
              "      <td>0.041319</td>\n",
              "      <td>0.184167</td>\n",
              "      <td>0.185312</td>\n",
              "      <td>0.140830</td>\n",
              "      <td>1.001304</td>\n",
              "      <td>0.033605</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.545051</td>\n",
              "      <td>0.263858</td>\n",
              "      <td>0.239840</td>\n",
              "      <td>-0.114119</td>\n",
              "      <td>-0.042218</td>\n",
              "      <td>0.036289</td>\n",
              "      <td>0.033605</td>\n",
              "      <td>1.001304</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          0         1         2         3         4         5         6  \\\n",
              "0  1.001304  0.129627  0.141466 -0.081778 -0.073630  0.017706 -0.033566   \n",
              "1  0.129627  1.001304  0.152789  0.057403  0.331789  0.221359  0.137516   \n",
              "2  0.141466  0.152789  1.001304  0.207641  0.089049  0.282173  0.041319   \n",
              "3 -0.081778  0.057403  0.207641  1.001304  0.437352  0.393085  0.184167   \n",
              "4 -0.073630  0.331789  0.089049  0.437352  1.001304  0.198117  0.185312   \n",
              "5  0.017706  0.221359  0.282173  0.393085  0.198117  1.001304  0.140830   \n",
              "6 -0.033566  0.137516  0.041319  0.184167  0.185312  0.140830  1.001304   \n",
              "7  0.545051  0.263858  0.239840 -0.114119 -0.042218  0.036289  0.033605   \n",
              "\n",
              "          7  \n",
              "0  0.545051  \n",
              "1  0.263858  \n",
              "2  0.239840  \n",
              "3 -0.114119  \n",
              "4 -0.042218  \n",
              "5  0.036289  \n",
              "6  0.033605  \n",
              "7  1.001304  "
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "covarianceMatrix = dataScaled.T @ dataScaled / 767\n",
        "covarianceMatrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**3. Evaluate the EigenValues and EigenVectors using the Covariance Matrix**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "eigenValues, eigenVectors = np.linalg.eig(covarianceMatrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([2.09711056, 1.73346726, 0.42036353, 0.40498938, 0.68351839,\n",
              "       0.76333832, 0.87667054, 1.03097228])"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## eigenValues = number of features\n",
        "eigenValues"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[-0.1284321 , -0.59378583, -0.58879003,  0.11784098, -0.19359817,\n",
              "         0.47560573, -0.08069115,  0.01308692],\n",
              "       [-0.39308257, -0.17402908, -0.06015291,  0.45035526, -0.09416176,\n",
              "        -0.46632804,  0.40432871, -0.46792282],\n",
              "       [-0.36000261, -0.18389207, -0.19211793, -0.01129554,  0.6341159 ,\n",
              "        -0.32795306, -0.05598649,  0.53549442],\n",
              "       [-0.43982428,  0.33196534,  0.28221253,  0.5662838 , -0.00958944,\n",
              "         0.48786206, -0.03797608,  0.2376738 ],\n",
              "       [-0.43502617,  0.25078106, -0.13200992, -0.54862138,  0.27065061,\n",
              "         0.34693481,  0.34994376, -0.33670893],\n",
              "       [-0.45194134,  0.1009598 , -0.03536644, -0.34151764, -0.68537218,\n",
              "        -0.25320376, -0.05364595,  0.36186463],\n",
              "       [-0.27061144,  0.122069  , -0.08609107, -0.00825873,  0.08578409,\n",
              "        -0.11981049, -0.8336801 , -0.43318905],\n",
              "       [-0.19802707, -0.62058853,  0.71208542, -0.21166198,  0.03335717,\n",
              "         0.10928996, -0.0712006 , -0.07524755]])"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "eigenVectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0     -1.068503\n",
              "1      1.121683\n",
              "2      0.396477\n",
              "3      1.115781\n",
              "4     -2.359334\n",
              "         ...   \n",
              "763   -1.562085\n",
              "764    0.100405\n",
              "765    0.283475\n",
              "766    1.060324\n",
              "767    0.839892\n",
              "Length: 768, dtype: float64"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## PC1 data\n",
        "PC1_data = dataScaled @ eigenVectors[:, 0]\n",
        "PC1_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0     -1.234895\n",
              "1      0.733852\n",
              "2     -1.595876\n",
              "3      1.271241\n",
              "4      2.184819\n",
              "         ...   \n",
              "763   -1.923150\n",
              "764    0.614181\n",
              "765   -0.097065\n",
              "766   -0.837062\n",
              "767    1.151755\n",
              "Length: 768, dtype: float64"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## PC2 data\n",
        "PC2_data = dataScaled @ eigenVectors[:, 1]\n",
        "PC2_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0     -0.095930\n",
              "1      0.712938\n",
              "2     -1.760678\n",
              "3      0.663729\n",
              "4     -2.963107\n",
              "         ...   \n",
              "763    0.867408\n",
              "764    0.764353\n",
              "765    0.077192\n",
              "766   -0.425030\n",
              "767    1.009178\n",
              "Length: 768, dtype: float64"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## PC3 data\n",
        "PC3_data = dataScaled @ eigenVectors[:, 7]\n",
        "PC3_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**PCA Implementation via the sklearn library**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 1.06850273,  1.23489499, -0.09592984],\n",
              "       [-1.12168331, -0.73385167,  0.71293816],\n",
              "       [-0.39647671,  1.59587594, -1.76067844],\n",
              "       ...,\n",
              "       [-0.28347525,  0.09706503,  0.07719194],\n",
              "       [-1.06032431,  0.83706234, -0.42503045],\n",
              "       [-0.83989172, -1.15175485,  1.00917817]])"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components=3)\n",
        "pca.fit_transform(dataScaled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "pca = PCA()\n",
        "principalComponent = pca.fit_transform(dataScaled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.26179749, 0.21640127, 0.12870373, 0.10944113, 0.09529305,\n",
              "       0.08532855, 0.05247702, 0.05055776])"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pca.explained_variance_ratio_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`pca.explained_variance_ratio_` is an attribute of the Principal Component Analysis (PCA) object in Python's `scikit-learn` library. It provides a measure of how much variance in the data is captured by each principal component after applying PCA. Specifically, it returns an array that represents the proportion (or percentage) of the total variance explained by each of the selected principal components.\n",
        "\n",
        "### Key Points:\n",
        "- **Variance**: In the context of PCA, variance refers to how spread out the data is along the principal component axes.\n",
        "- **Principal Components**: These are the new axes (or directions) in the data that maximize the variance after transforming the original features.\n",
        "- **Explained Variance Ratio**: Each principal component explains a certain amount of the variance in the dataset. `pca.explained_variance_ratio_` tells you how much of the total variance is explained by each component.\n",
        "\n",
        "### Example:\n",
        "\n",
        "Suppose you perform PCA on a dataset with 5 features, and you select 2 principal components. After running the PCA, you get the following result:\n",
        "\n",
        "```python\n",
        "pca.explained_variance_ratio_\n",
        "```\n",
        "\n",
        "The output might look something like this:\n",
        "```python\n",
        "array([0.6, 0.3])\n",
        "```\n",
        "\n",
        "This tells us:\n",
        "- The first principal component explains 60% of the variance in the dataset.\n",
        "- The second principal component explains 30% of the variance.\n",
        "  \n",
        "Together, the two components explain 90% of the total variance in the data.\n",
        "\n",
        "### Usefulness:\n",
        "- **Dimensionality Reduction**: `explained_variance_ratio_` helps you decide how many components to keep by showing the variance explained by each. For example, you might decide to keep enough components to explain 95% of the variance.\n",
        "- **Model Interpretation**: It helps to understand the importance of each principal component and how well they capture the underlying structure of the data.\n",
        "\n",
        "In summary, `pca.explained_variance_ratio_` tells you how much of the variability in your data is captured by each of the principal components and helps in determining the optimal number of components to retain."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
        "plt.xlabel(\"Dimensions\")\n",
        "plt.ylabel(\"Explained Variance Ratio\")\n",
        "plt.savefig(\"ScreenPlot.png\")\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Encoding Techniques in Machine Learning**\n",
        "\n",
        "In machine learning, most algorithms require numeric input. However, categorical data, like city names or colors, is often represented as text or labels. **Encoding techniques** are used to transform these categorical features into a format that can be provided to machine learning algorithms.\n",
        "\n",
        "### 1. **Label Encoding**\n",
        "Label Encoding assigns a unique integer to each category in the data. This method transforms categorical values into numerical labels. It’s useful when the categorical data has some order or ranking. However, it can sometimes create unintended ordinal relationships between categories.\n",
        "\n",
        "#### How it works:\n",
        "- Each unique category is assigned an integer value starting from 0.\n",
        "- No new features are created, and the original categorical feature is simply replaced by integer values.\n",
        "\n",
        "#### Example:\n",
        "Imagine you have a column `Colors` with three categories: \"Red,\" \"Blue,\" and \"Green.\"\n",
        "\n",
        "| Color  | Label Encoded |\n",
        "|--------|---------------|\n",
        "| Red    | 0             |\n",
        "| Blue   | 1             |\n",
        "| Green  | 2             |\n",
        "\n",
        "#### Pros:\n",
        "- Simple and memory-efficient as it does not increase the dimensionality.\n",
        "  \n",
        "#### Cons:\n",
        "- Imposes an ordinal relationship between categories, which might mislead the model if there is no actual ranking.\n",
        "\n",
        "#### Code Example:\n",
        "```python\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Example data\n",
        "data = ['Red', 'Blue', 'Green', 'Blue', 'Red']\n",
        "\n",
        "# Initialize the LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Fit and transform the data\n",
        "encoded_data = label_encoder.fit_transform(data)\n",
        "\n",
        "print(encoded_data)\n",
        "```\n",
        "\n",
        "### 2. **One-Hot Encoding**\n",
        "One-Hot Encoding transforms categorical variables into multiple binary columns, where each column represents a unique category. If a category is present in a row, the corresponding column gets a value of 1, and all other columns get a value of 0.\n",
        "\n",
        "#### How it works:\n",
        "- For each unique category, a new column is created.\n",
        "- Each column represents one of the categories, and it has binary values (0 or 1).\n",
        "\n",
        "#### Example:\n",
        "Using the same `Colors` column with values: \"Red,\" \"Blue,\" and \"Green\":\n",
        "\n",
        "| Color  | Red | Blue | Green |\n",
        "|--------|-----|------|-------|\n",
        "| Red    |  1  |   0  |   0   |\n",
        "| Blue   |  0  |   1  |   0   |\n",
        "| Green  |  0  |   0  |   1   |\n",
        "\n",
        "#### Pros:\n",
        "- Avoids introducing ordinal relationships, making it better suited for nominal categorical features.\n",
        "  \n",
        "#### Cons:\n",
        "- Can lead to **high-dimensionality** if there are many unique categories (curse of dimensionality).\n",
        "- Memory-inefficient when dealing with a large number of categories.\n",
        "\n",
        "#### Code Example:\n",
        "```python\n",
        "import pandas as pd\n",
        "\n",
        "# Example data\n",
        "data = {'Color': ['Red', 'Blue', 'Green', 'Blue', 'Red']}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Perform One-Hot Encoding\n",
        "one_hot_encoded_data = pd.get_dummies(df['Color'])\n",
        "\n",
        "print(one_hot_encoded_data)\n",
        "```\n",
        "\n",
        "### When to Use:\n",
        "- **Label Encoding**: Best suited for ordinal categorical variables where the categories have a meaningful order. For example, \"Low,\" \"Medium,\" and \"High.\"\n",
        "- **One-Hot Encoding**: Ideal for **nominal** categorical variables (no natural order), such as colors, product categories, or city names. It’s commonly used in tree-based models and deep learning algorithms.\n",
        "\n",
        "### Which Technique to Use?\n",
        "\n",
        "- **Use Label Encoding** when there’s an **ordinal relationship** between categories (i.e., the categories have some inherent ranking, like `low`, `medium`, `high`).\n",
        "  \n",
        "- **Use One-Hot Encoding** when the categories are **nominal** (no order between them) and there’s no relationship or ranking between the categories.\n",
        "\n",
        "### Summary:\n",
        "- **Label Encoding** is simple and works well when the categorical feature has a natural order.\n",
        "- **One-Hot Encoding** is preferable for features that do not have an inherent order but can increase the feature space significantly.\n",
        "\n",
        "Each technique is useful in different situations, and the choice depends on the specific nature of the categorical data and the machine learning model being used."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1iJPf7m7MGE",
        "outputId": "74c2ef71-9cf5-4c1e-b508-c8b91308a24b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Color\n",
            "0    Red\n",
            "1   Blue\n",
            "2  Green\n",
            "3   Blue\n",
            "4    Red\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "data = {'Color':['Red', 'Blue', 'Green', 'Blue', 'Red']}\n",
        "dataframe = pd.DataFrame(data)\n",
        "print(dataframe)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_KMmFgFq7L-2",
        "outputId": "444a1b2d-3695-4558-c1c7-a93a5a64bc67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Color_Blue  Color_Green  Color_Red\n",
            "0       False        False       True\n",
            "1        True        False      False\n",
            "2       False         True      False\n",
            "3        True        False      False\n",
            "4       False        False       True\n"
          ]
        }
      ],
      "source": [
        "one_hot_encoded_df = pd.get_dummies(dataframe, columns=['Color'])\n",
        "print(one_hot_encoded_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qqKDiL07xs6"
      },
      "source": [
        "Dummy Variable Trap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hc1WVqWM70rI",
        "outputId": "f9bd763d-ffb9-46ea-bd22-7087e7785d4a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Color_Green  Color_Red\n",
            "0        False       True\n",
            "1        False      False\n",
            "2         True      False\n",
            "3        False      False\n",
            "4        False       True\n"
          ]
        }
      ],
      "source": [
        "## avoid the redundant information and get rid of the multicollinearity\n",
        "one_hot_encoded_df = pd.get_dummies(dataframe, columns=['Color'], drop_first=True)\n",
        "print(one_hot_encoded_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEPP7IFbv2Rl",
        "outputId": "6a092123-9990-4bbe-9e9f-3e6877a634ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original Data:\n",
            "                 Car Model  Mileage  Sell Price($)  Age(yrs)\n",
            "0                  BMW X5    69000          18000         6\n",
            "1                  BMW X5    35000          34000         3\n",
            "2                  BMW X5    57000          26100         5\n",
            "3                  BMW X5    22500          40000         2\n",
            "4                  BMW X5    46000          31500         4\n",
            "5                 Audi A5    59000          29400         5\n",
            "6                 Audi A5    52000          32000         5\n",
            "7                 Audi A5    72000          19300         6\n",
            "8                 Audi A5    91000          12000         8\n",
            "9   Mercedez Benz C class    67000          22000         6\n",
            "10  Mercedez Benz C class    83000          20000         7\n",
            "11  Mercedez Benz C class    79000          21000         7\n",
            "12  Mercedez Benz C class    59000          33000         5\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
        "\n",
        "# Load the dataset\n",
        "file_path = './carprices.csv'\n",
        "car_data = pd.read_csv(file_path)\n",
        "\n",
        "# Display the first few rows of the dataset to understand its structure\n",
        "print(\"Original Data:\\n\", car_data.head(14))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "id": "v4zS5vcX8V2j",
        "outputId": "997e8a60-7c39-4dbc-ce03-3a6ed804aad1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Car Model        object\n",
              "Mileage           int64\n",
              "Sell Price($)     int64\n",
              "Age(yrs)          int64\n",
              "dtype: object"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "car_data.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9FcsYsFw8bH5",
        "outputId": "bce224a6-c9a9-4391-d9ae-0abebeaa99ec"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(13, 4)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "car_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RBQBx9XrxBdB",
        "outputId": "a5dd62f0-6049-4946-9dde-9ba69b0022fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "One-Hot Encoded Data:\n",
            "                 Car Model  Mileage  Sell Price($)  Age(yrs)  \\\n",
            "0                  BMW X5    69000          18000         6   \n",
            "1                  BMW X5    35000          34000         3   \n",
            "2                  BMW X5    57000          26100         5   \n",
            "3                  BMW X5    22500          40000         2   \n",
            "4                  BMW X5    46000          31500         4   \n",
            "5                 Audi A5    59000          29400         5   \n",
            "6                 Audi A5    52000          32000         5   \n",
            "7                 Audi A5    72000          19300         6   \n",
            "8                 Audi A5    91000          12000         8   \n",
            "9   Mercedez Benz C class    67000          22000         6   \n",
            "10  Mercedez Benz C class    83000          20000         7   \n",
            "11  Mercedez Benz C class    79000          21000         7   \n",
            "12  Mercedez Benz C class    59000          33000         5   \n",
            "\n",
            "    Car Model_Audi A5  Car Model_BMW X5  Car Model_Mercedez Benz C class  \n",
            "0                 0.0               1.0                              0.0  \n",
            "1                 0.0               1.0                              0.0  \n",
            "2                 0.0               1.0                              0.0  \n",
            "3                 0.0               1.0                              0.0  \n",
            "4                 0.0               1.0                              0.0  \n",
            "5                 1.0               0.0                              0.0  \n",
            "6                 1.0               0.0                              0.0  \n",
            "7                 1.0               0.0                              0.0  \n",
            "8                 1.0               0.0                              0.0  \n",
            "9                 0.0               0.0                              1.0  \n",
            "10                0.0               0.0                              1.0  \n",
            "11                0.0               0.0                              1.0  \n",
            "12                0.0               0.0                              1.0  \n"
          ]
        }
      ],
      "source": [
        "# Extract the 'Car Model' column\n",
        "car_models = car_data[['Car Model']]\n",
        "\n",
        "# Apply One-Hot Encoding\n",
        "one_hot_encoder = OneHotEncoder(sparse_output=False)\n",
        "one_hot_encoded = one_hot_encoder.fit_transform(car_models)\n",
        "\n",
        "# Convert one-hot encoding result to DataFrame\n",
        "one_hot_encoded_df = pd.DataFrame(one_hot_encoded, columns=one_hot_encoder.get_feature_names_out(['Car Model']))\n",
        "\n",
        "# Combine the one-hot encoded columns with the original data\n",
        "car_data_one_hot_encoded = pd.concat([car_data, one_hot_encoded_df], axis=1)\n",
        "\n",
        "# Display the one-hot encoded data\n",
        "print(\"\\nOne-Hot Encoded Data:\\n\", car_data_one_hot_encoded.head(14))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pES82wJzxLgG",
        "outputId": "dca98909-4fdd-482e-a255-05af2f70c019"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Label Encoded Data:\n",
            "                 Car Model  Mileage  Sell Price($)  Age(yrs)  \\\n",
            "0                  BMW X5    69000          18000         6   \n",
            "1                  BMW X5    35000          34000         3   \n",
            "2                  BMW X5    57000          26100         5   \n",
            "3                  BMW X5    22500          40000         2   \n",
            "4                  BMW X5    46000          31500         4   \n",
            "5                 Audi A5    59000          29400         5   \n",
            "6                 Audi A5    52000          32000         5   \n",
            "7                 Audi A5    72000          19300         6   \n",
            "8                 Audi A5    91000          12000         8   \n",
            "9   Mercedez Benz C class    67000          22000         6   \n",
            "10  Mercedez Benz C class    83000          20000         7   \n",
            "11  Mercedez Benz C class    79000          21000         7   \n",
            "12  Mercedez Benz C class    59000          33000         5   \n",
            "\n",
            "    Car Model (Label Encoded)  \n",
            "0                           1  \n",
            "1                           1  \n",
            "2                           1  \n",
            "3                           1  \n",
            "4                           1  \n",
            "5                           0  \n",
            "6                           0  \n",
            "7                           0  \n",
            "8                           0  \n",
            "9                           2  \n",
            "10                          2  \n",
            "11                          2  \n",
            "12                          2  \n"
          ]
        }
      ],
      "source": [
        "# Apply Label Encoding\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoded = label_encoder.fit_transform(car_models['Car Model'])\n",
        "\n",
        "# Add the label encoded column to the original data\n",
        "car_data_label_encoded = car_data.copy()\n",
        "car_data_label_encoded['Car Model (Label Encoded)'] = label_encoded\n",
        "\n",
        "# Display the label encoded data\n",
        "print(\"\\nLabel Encoded Data:\\n\", car_data_label_encoded.head(14))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
